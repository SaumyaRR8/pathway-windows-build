{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-colab"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathwaycom/pathway/blob/main/examples/notebooks/tutorials/fs_connector.ipynb\" target=\"_parent\"><img src=\"https://pathway.com/assets/colab-badge.svg\" alt=\"Run In Colab\" class=\"inline\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Pathway with Python 3.10+\n",
        "\n",
        "In the cell below, we install Pathway into a Python 3.10+ Linux runtime.\n",
        "\n",
        "> **If you are running in Google Colab, please run the colab notebook (Ctrl+F9)**, disregarding the 'not authored by Google' warning.\n",
        "> \n",
        "> **The installation and loading time is less than 1 minute**.\n"
      ],
      "metadata": {
        "id": "notebook-instructions"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-display\n",
        "!pip install --prefer-binary pathway"
      ],
      "metadata": {
        "id": "pip-installation-pathway",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "license-key",
      "source": [
        "import pathway as pw\n",
        "\n",
        "# To use advanced features with Pathway Scale, get your free license key from\n",
        "# https://pathway.com/features and paste it below.\n",
        "# To use Pathway Community, comment out the line below.\n",
        "pw.set_license_key(\"demo-license-key-with-telemetry\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {},
      "source": [
        "# File System Connectors\n",
        "This guide explains the [fs connectors](/developers/api-docs/pathway-io/fs) that connect Pathway to your file system to read and write data with the following basic formats: binary, plaintext, CSV, and JSON.\n",
        "\n",
        "The first part of this guide focuses on defining the source of the data for our connector (using plaintext data format to keep things simple). The second part explains additional configuration that can (or needs to) be defined for all simple data formats.\n",
        "In particular we show the input connectors ([`pw.io.fs.read`](/developers/api-docs/pathway-io/fs#pathway.io.fs.read)) reading data in:\n",
        "- [`CSV` format](/developers/user-guide/connect/connectors/fs-connector#csv),\n",
        "- [`JSON` format](/developers/user-guide/connect/connectors/fs-connector#json),\n",
        "- [`plaintext`, `plaintext_by_file`, and `binary` formats](/developers/user-guide/connect/connectors/fs-connector#unstructured-data).\n",
        "\n",
        "The output connectors ([`pw.io.fs.write`](/developers/api-docs/pathway-io/fs#pathway.io.fs.write)) write data in:\n",
        "- [`CSV` format](/developers/user-guide/connect/connectors/fs-connector#csv),\n",
        "- [`JSON` format](/developers/user-guide/connect/connectors/fs-connector#json).\n",
        "\n",
        "File system connectors work both in streaming and static modes. Be careful as the use of connectors differs depending on the chosen mode: see the [differences](/developers/user-guide/introduction/streaming-and-static-modes).\n",
        "For simplicity, all the examples below are in the \"static\" mode but can easily be changed to \"streaming\" mode by changing the `mode` parameter.\n",
        "\n",
        "## Location of files and filter.\n",
        "The code snippets below prepares the basic file structure that is used in the later part of this article. To keep tings simple, all examples work with data of type `str`, to see more on [schemas](/developers/user-guide/connect/schema) and [types](/developers/user-guide/connect/datatypes) in other places."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "! mkdir -p plain_input\n",
        "! mkdir -p plain_output\n",
        "! echo -e \"test1\\ndata1\" > plain_input/in1.txt\n",
        "! echo -e \"test2\\ndata2\" > plain_input/in2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3",
      "metadata": {},
      "source": [
        "### Specify the input and output with `path` and `filename`.\n",
        "Below, you can find the simplest examples of input ([`pw.io.fs.read`](/developers/api-docs/pathway-io/fs#pathway.io.fs.read)) and output ([`pw.io.fs.write`](/developers/api-docs/pathway-io/fs#pathway.io.fs.write)) connectors. Both examples use plaintext as the input format (more on that [later](/developers/user-guide/connect/connectors/fs-connector#data-formats)). The `path` parameter can point either to a directory or a particular file. If it point so a directory, it reads all files that are inside. Otherwise it reads only the file that is specified (and as such it makes sense only in the static mode)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import pathway as pw\n",
        "test1 = pw.io.fs.read(path = \"./plain_input/\", format = \"plaintext\", mode=\"static\")\n",
        "pw.io.fs.write(test1, filename=\"./plain_output/out1.txt\", format=\"json\")\n",
        "\n",
        "test2 = pw.io.fs.read(path = \"./plain_input/in1.txt\", format = \"plaintext\", mode=\"static\")\n",
        "pw.io.fs.write(test2, filename=\"./plain_output/out2.txt\", format=\"json\")\n",
        "\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {},
      "source": [
        "The output can be found in the `plain_output` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out1:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"data\":\"test1\",\"diff\":1,\"time\":1718253318162}\r\n",
            "{\"data\":\"data2\",\"diff\":1,\"time\":1718253318162}\r\n",
            "{\"data\":\"data1\",\"diff\":1,\"time\":1718253318162}\r\n",
            "{\"data\":\"test2\",\"diff\":1,\"time\":1718253318162}\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out2:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"data\":\"test1\",\"diff\":1,\"time\":1718253318162}\r\n",
            "{\"data\":\"data1\",\"diff\":1,\"time\":1718253318162}\r\n"
          ]
        }
      ],
      "source": [
        "! echo \"out1:\"\n",
        "! cat plain_output/out1.txt\n",
        "! echo \"out2:\"\n",
        "! cat plain_output/out2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "As you can see, the first example read the data from both `in1.txt` and `in2.txt`, while the second read only the data from `in1.txt`.\n",
        "\n",
        "### Filter the files to read with `object_pattern`\n",
        "In case you want to specify a directory as the source of your data, but read only some of its contents, you can specify filter [pattern](https://www.gnu.org/software/findutils/manual/html_node/find_html/Shell-Pattern-Matching.html) and pass it using the `object_pattern` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "test3 = pw.io.fs.read(\"./plain_input/\", format = \"plaintext\", mode=\"static\", object_pattern = \"*2*\")\n",
        "pw.io.fs.write(test3, \"./plain_output/output3.txt\", \"json\")\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {},
      "source": [
        "The output can be found in the `plain_output` directory. As you can see, `out3.txt` contains data only from `in2.txt`, as it is the only file in the input directory that matches the `*2*` pattern:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out3:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"data\":\"data2\",\"diff\":1,\"time\":1718253318760}\r\n",
            "{\"data\":\"test2\",\"diff\":1,\"time\":1718253318760}\r\n"
          ]
        }
      ],
      "source": [
        "! echo \"out3:\"\n",
        "! cat plain_output/output3.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {},
      "source": [
        "## Data formats\n",
        "### CSV\n",
        "For the CSV format, each file on the input needs to have defined headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "csv_in1.txt:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "header1;header2\r\n",
            "data1;data2\r\n",
            "\r\n",
            "data3;data4\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "csv_in2.txt:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "header1;header2\r\n",
            "data5;data6\r\n",
            "\r\n",
            "data7;data8\r\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p csv_input\n",
        "! mkdir -p csv_output\n",
        "! echo -e \"header1;header2\\ndata1;data2\\n\\ndata3;data4\" > csv_input/csv_in1.txt\n",
        "! echo -e \"header1;header2\\ndata5;data6\\n\\ndata7;data8\" > csv_input/csv_in2.txt\n",
        "! echo -e \"csv_in1.txt:\"\n",
        "! cat csv_input/csv_in1.txt\n",
        "! echo -e \"csv_in2.txt:\"\n",
        "! cat csv_input/csv_in2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "In most cases, in order to read the data, you need to define its schema and pass it to the connector. Furthermore, for the `csv` format, you can use [CSVParserSettings](/developers/api-docs/pathway-io#pathway.io.CsvParserSettings) to accommodate for a nonstandard formatting of the input file. In the example below, it is configured to use `;` as a delimiter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "class csv_schema(pw.Schema):\n",
        "    header1: str\n",
        "    header2: str\n",
        "\n",
        "csv_settings = pw.io.CsvParserSettings(delimiter=\";\")\n",
        "csv_data = pw.io.fs.read(path = \"./csv_input/\", format=\"csv\", schema=csv_schema, csv_settings=csv_settings,mode=\"static\")\n",
        "pw.io.fs.write(table=csv_data, filename=\"./csv_output/csv_out1.txt\", format=\"csv\")\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "header1,header2,time,diff\r\n",
            "\"data7\",\"data8\",1718253320224,1\r\n",
            "\"data1\",\"data2\",1718253320224,1\r\n",
            "\"data3\",\"data4\",1718253320224,1\r\n",
            "\"data5\",\"data6\",1718253320224,1\r\n"
          ]
        }
      ],
      "source": [
        "! cat ./csv_output/csv_out1.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "You can also use the dedicated [CSV connector](/developers/user-guide/connect/connectors/csv_connectors).\n",
        "### JSON\n",
        "You can use the [JSON format](https://json.org) by setting the parameter `format` to `json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "json_in1.txt:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"header1\":data1\",\r\n",
            "\"header2\":\"data2\"}\r\n",
            "{\"header1\":\"data3\",\"header2\":\"data4\"}\r\n",
            "\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "json_in2.txt:\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"header1\":\"data5\",\"header2\":\"data6\"}\r\n",
            "{\"header1\":\"data7\",\"header2\":\"data8\"}\r\n",
            "\r\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p json_input\n",
        "! mkdir -p json_output\n",
        "! echo -e '{\"header1\":data1\",\\n\"header2\":\"data2\"}\\n{\"header1\":\"data3\",\"header2\":\"data4\"}\\n' > json_input/json_in1.txt\n",
        "! echo -e '{\"header1\":\"data5\",\"header2\":\"data6\"}\\n{\"header1\":\"data7\",\"header2\":\"data8\"}\\n' > json_input/json_in2.txt\n",
        "! echo -e \"json_in1.txt:\"\n",
        "! cat json_input/json_in1.txt\n",
        "! echo -e \"json_in2.txt:\"\n",
        "! cat json_input/json_in2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "As in most cases, in order to read the data, you need to define a schema and pass it to the connector. Each input file needs to be a sequence of properly formatted JSON objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "class json_schema(pw.Schema):\n",
        "    header1: str\n",
        "    header2: str\n",
        "\n",
        "json_data = pw.io.fs.read(path = \"./json_input/\", format=\"json\", schema=json_schema, mode=\"static\")\n",
        "pw.io.fs.write(table=json_data, filename=\"./json_output/json_out1.txt\", format=\"json\")\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"header1\":\"data7\",\"header2\":\"data8\",\"diff\":1,\"time\":1718253321550}\r\n",
            "{\"header1\":\"data3\",\"header2\":\"data4\",\"diff\":1,\"time\":1718253321550}\r\n",
            "{\"header1\":\"data5\",\"header2\":\"data6\",\"diff\":1,\"time\":1718253321550}\r\n"
          ]
        }
      ],
      "source": [
        "! cat ./json_output/json_out1.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "### Unstructured data\n",
        "Pathway allows you to read unstructured data using three formats: `plaintext`, `plaintext_by_file`, and  `binary`. `binary` and `plaintext` considers each line as a separate row that will be stored in the column `data`, and the format `plaintext_by_file` treats each file as a single row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22",
      "metadata": {},
      "outputs": [],
      "source": [
        "! mkdir -p unstructured_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "plaintext_data = pw.io.fs.read(path = \"./plain_input\", format = \"plaintext\", mode=\"static\")\n",
        "pw.io.fs.write(plaintext_data,\"./unstructured_output/output1.txt\", \"csv\")\n",
        "\n",
        "plaintext_by_file_data = pw.io.fs.read(path = \"./plain_input\", format = \"plaintext_by_file\", mode=\"static\")\n",
        "pw.io.fs.write(plaintext_by_file_data,\"./unstructured_output/output2.txt\", \"csv\")\n",
        "\n",
        "binary_data = pw.io.fs.read(path = \"./plain_input\", format = \"binary\", mode=\"static\")\n",
        "pw.io.fs.write(binary_data,\"./unstructured_output/output3.txt\", \"csv\")\n",
        "\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24",
      "metadata": {
        "lines_to_next_cell": 3
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plaintext\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data,time,diff\r\n",
            "\"test1\",1718253321866,1\r\n",
            "\"data2\",1718253321866,1\r\n",
            "\"data1\",1718253321866,1\r\n",
            "\"test2\",1718253321866,1\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plaintext by file\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data,time,diff\r\n",
            "\"test2\\ndata2\",1718253321866,1\r\n",
            "\"test1\\ndata1\",1718253321866,1\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary\r\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data,time,diff\r\n",
            "[116, 101, 115, 116, 50, 10, 100, 97, 116, 97, 50, 10],1718253321866,1\r\n",
            "[116, 101, 115, 116, 49, 10, 100, 97, 116, 97, 49, 10],1718253321866,1\r\n"
          ]
        }
      ],
      "source": [
        "! echo \"plaintext\"\n",
        "! cat ./unstructured_output/output1.txt\n",
        "! echo \"plaintext by file\"\n",
        "! cat ./unstructured_output/output2.txt\n",
        "! echo \"binary\"\n",
        "! cat ./unstructured_output/output3.txt"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}